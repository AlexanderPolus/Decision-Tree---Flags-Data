{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib3\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data\n",
    "cols = ['name','landmass','zone', 'area', 'population', 'language','religion','bars','stripes','colours',\n",
    "'red','green','blue','gold','white','black','orange','mainhue','circles',\n",
    "'crosses','saltires','quarters','sunstars','crescent','triangle','icon','animate','text','topleft','botright']\n",
    "df= pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data\", names = cols)\n",
    "\n",
    "#variable names to use as predictors\n",
    "var = [ 'red', 'green', 'blue','gold', 'white', 'black', 'orange', 'mainhue','bars','stripes', 'circles','crosses', 'saltires','quarters','sunstars','triangle','animate']\n",
    "\n",
    "#Print number of countries by landmass, or continent\n",
    "print(\"Number of countries by continent\")\n",
    "print(df['landmass'].value_counts())\n",
    "\n",
    "#Create a new dataframe with only flags from Europe and Oceania\n",
    "df_36 = df[df['landmass'].isin([3, 6])]\n",
    "\n",
    "#Print the average values of the predictors for Europe and Oceania\n",
    "print(\"Average values of predictors for Europe and Oceania\")\n",
    "df_avg_36 = df_36.groupby('landmass')[var].mean()\n",
    "print(df_avg_36)\n",
    "\n",
    "#Create labels for only Europe and Oceania\n",
    "labels = df['landmass'].isin([3,6])\n",
    "\n",
    "#Print the variable types for the predictors\n",
    "dtypes = df_36[var].dtypes\n",
    "print(\"Data types of predictor variables:\")\n",
    "print(dtypes)\n",
    "\n",
    "#Create dummy variables for categorical predictors\n",
    "data = pd.get_dummies(df[var])\n",
    "print(\"One hot encoding of predictor variables:\")\n",
    "print(data.head())\n",
    "#Split data into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=1, test_size=0.4)\n",
    "\n",
    "#Fit a decision tree for max_depth values 1-20; save the accuracy score in acc_depth\n",
    "acc_depth = []\n",
    "depths = range(1, 21)\n",
    "for depth in depths:\n",
    "  dt = DecisionTreeClassifier(max_depth=depth)\n",
    "  dt.fit(X_train, y_train)\n",
    "  acc = dt.score(X_test, y_test)\n",
    "  acc_depth.append(acc)\n",
    "\n",
    "#Plot the accuracy vs depth\n",
    "plt.plot(depths, acc_depth)\n",
    "plt.xlabel(\"Depth of Decision Tree\")\n",
    "plt.ylabel(\"Accuract of Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "#Find the largest accuracy and the depth this occurs\n",
    "idx = acc_depth.index(np.max(acc_depth))\n",
    "print(\"IDX: %f\" % idx)\n",
    "optimal_depth = idx + 1\n",
    "print(\"Optimal depth:\")\n",
    "print(optimal_depth)\n",
    "\n",
    "#Refit decision tree model with the highest accuracy and plot the decision tree\n",
    "dt = DecisionTreeClassifier(max_depth = optimal_depth)\n",
    "dt.fit(X_train, y_train)\n",
    "tree.plot_tree(dt, feature_names=var)\n",
    "plt.show()\n",
    "#Create a new list for the accuracy values of a pruned decision tree.  Loop through\n",
    "#the values of ccp and append the scores to the list\n",
    "acc_pruned = []\n",
    "ccp = [x/100 for x in range(1, 100)]# [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "for value in ccp:\n",
    "  dt = DecisionTreeClassifier(max_depth=optimal_depth, ccp_alpha=value)\n",
    "  dt.fit(X_train, y_train)\n",
    "  acc = dt.score(X_test, y_test)\n",
    "  acc_pruned.append(acc)\n",
    "#Plot the accuracy vs ccp_alpha\n",
    "plt.figure()\n",
    "plt.plot(ccp, acc_pruned)\n",
    "plt.xlabel(\"CCP alpha Value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs CCP Alpha Value\")\n",
    "plt.show()\n",
    "\n",
    "#Find the largest accuracy and the ccp value this occurs\n",
    "largest = np.max(acc_pruned)\n",
    "optimal_ccp = ccp[acc_pruned.index(largest)]\n",
    "print(\"Optimal CCP:\")\n",
    "print(optimal_ccp)\n",
    "\n",
    "#Fit a decision tree model with the values for max_depth and ccp_alpha found above\n",
    "dt = DecisionTreeClassifier(max_depth=optimal_depth, ccp_alpha=optimal_ccp)\n",
    "dt.fit(X_train, y_train)\n",
    "plt.figure()\n",
    "tree.plot_tree(dt, feature_names=var)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Plot the final decision tree\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
